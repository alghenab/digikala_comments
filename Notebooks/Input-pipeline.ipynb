{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Input-pipeline.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1aWVVxK_QqZcXm3Ej2EMeq1zRXILQ3aaK","authorship_tag":"ABX9TyMo4kS7OBgA2bl0ms646OtH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Input Pipline\n","\n","As we're using TensorFlow we can make use of the `tf.data.Dataset` object. First, we'll load in our Numpy binaries from file:"],"metadata":{"id":"tXiLBirJVihp"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"9-av3UdIU4wG","executionInfo":{"status":"ok","timestamp":1649126811004,"user_tz":-270,"elapsed":6104,"user":{"displayName":"Mahdi Abdi","userId":"10554814127819121301"}}},"outputs":[],"source":["import numpy as np\n","\n","with open('/content/Digikala-comments/files/movie-xids.npy', 'rb') as f:\n","    Xids = np.load(f, allow_pickle=True)\n","with open('/content/Digikala-comments/files/movie-xmask.npy', 'rb') as f:\n","    Xmask = np.load(f, allow_pickle=True)\n","with open('/content/Digikala-comments/files/movie-labels.npy', 'rb') as f:\n","    labels = np.load(f, allow_pickle=True)"]},{"cell_type":"markdown","source":["We can take these three arrays and create a TF dataset object with them using `from_tensor_slices` like so:"],"metadata":{"id":"Ib3noELtVuAw"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n","\n","dataset.take(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5SzojLEDVfrj","executionInfo":{"status":"ok","timestamp":1649126820512,"user_tz":-270,"elapsed":6911,"user":{"displayName":"Mahdi Abdi","userId":"10554814127819121301"}},"outputId":"54fd1797-d45f-4fe7-949a-c155ad5c83ca"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(6,), dtype=tf.float64, name=None))>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["To rearrange the dataset format we can `map` a function that modifies the format like so:"],"metadata":{"id":"iaY2g9TVV6VZ"}},{"cell_type":"code","source":["def map_func(input_ids, masks, labels):\n","    # we convert our three-item tuple into a two-item tuple where the input item is a dictionary\n","    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n","\n","# then we use the dataset map method to apply this transformation\n","dataset = dataset.map(map_func)\n","\n","dataset.take(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9OpeZhlwV-tw","executionInfo":{"status":"ok","timestamp":1649126820513,"user_tz":-270,"elapsed":12,"user":{"displayName":"Mahdi Abdi","userId":"10554814127819121301"}},"outputId":"63e61611-a709-4f2e-af42-b940b817dc28"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int64, name=None)}, TensorSpec(shape=(6,), dtype=tf.float64, name=None))>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Now we can see that our dataset sample format has been changed. Next, we need to shuffle our data, and batch it. We will take batch sizes of 3 and drop any samples that don't fit evenly into chunks of 3"],"metadata":{"id":"KwthaEKyWHJD"}},{"cell_type":"code","source":["batch_size = 50\n","\n","dataset = dataset.shuffle(1000).batch(batch_size, drop_remainder=True)\n","\n","dataset.take(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNeestW5WC72","executionInfo":{"status":"ok","timestamp":1649126822085,"user_tz":-270,"elapsed":9,"user":{"displayName":"Mahdi Abdi","userId":"10554814127819121301"}},"outputId":"cf500ee9-4410-4984-ec46-152c9f3ac108"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(50, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(50, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(50, 6), dtype=tf.float64, name=None))>"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Now our dataset samples are organized into batches of 3. The final step is to split our data into training and validation sets. For this we use the take and skip methods, creating and 90-10 split."],"metadata":{"id":"GvxQVYqdWK3g"}},{"cell_type":"code","source":["split = 0.9\n","\n","# we need to calculate how many batches must be taken to create 90% training set\n","size = int((Xids.shape[0] / batch_size) * split)\n","\n","size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ioJMfUVbWLl9","executionInfo":{"status":"ok","timestamp":1649126841597,"user_tz":-270,"elapsed":639,"user":{"displayName":"Mahdi Abdi","userId":"10554814127819121301"}},"outputId":"822a8144-9bfc-40c5-e132-7b6fb09de9e1"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3228"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["train_ds = dataset.take(size)\n","val_ds = dataset.skip(size)"],"metadata":{"id":"GPKlwCxxWPdF","executionInfo":{"status":"ok","timestamp":1649126854333,"user_tz":-270,"elapsed":477,"user":{"displayName":"Mahdi Abdi","userId":"10554814127819121301"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Our two datasets are fully prepared for our model inputs. Now, we can save both to file using `tf.data.experimental.save`."],"metadata":{"id":"2FjDerxLWSUK"}},{"cell_type":"code","source":["# tf.data.experimental.save(train_ds, 'train')\n","# tf.data.experimental.save(val_ds, 'val')"],"metadata":{"id":"-U8RnPp9WR-Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the next notebook we will be loading these files using `tf.data.experimental.load`. Which requires us to define the tensor `element_spec` - which describes the tensor shape. To find our dataset element spec we can write:"],"metadata":{"id":"fTNvjcu0WaPi"}},{"cell_type":"code","source":["train_ds.element_spec"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ks15iPtbWW2Y","executionInfo":{"status":"ok","timestamp":1649126872812,"user_tz":-270,"elapsed":452,"user":{"displayName":"Mahdi Abdi","userId":"10554814127819121301"}},"outputId":"10008186-6841-4028-c1ac-1f03cc5a2be4"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'attention_mask': TensorSpec(shape=(50, 512), dtype=tf.int64, name=None),\n","  'input_ids': TensorSpec(shape=(50, 512), dtype=tf.int64, name=None)},\n"," TensorSpec(shape=(50, 6), dtype=tf.float64, name=None))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["val_ds.element_spec == train_ds.element_spec"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTF0vqS1WiMv","executionInfo":{"status":"ok","timestamp":1649126878278,"user_tz":-270,"elapsed":478,"user":{"displayName":"Mahdi Abdi","userId":"10554814127819121301"}},"outputId":"09851225-a56f-43b8-ba7e-fded696b951a"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["We will be using this tuple when loading our data in the next notebook."],"metadata":{"id":"kEPacYXIWlrY"}},{"cell_type":"code","source":["# ds = tf.data.experimental.load('train', element_spec=train_ds.element_spec)"],"metadata":{"id":"IKcDNhxaWjnf","executionInfo":{"status":"ok","timestamp":1649126925087,"user_tz":-270,"elapsed":518,"user":{"displayName":"Mahdi Abdi","userId":"10554814127819121301"}}},"execution_count":11,"outputs":[]}]}